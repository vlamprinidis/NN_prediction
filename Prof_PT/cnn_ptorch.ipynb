{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.7/site-packages/torch/nn/parallel/__init__.py:12: UserWarning: torch.nn.parallel.DistributedDataParallelCPU is deprecated, please use torch.nn.parallel.DistributedDataParallel instead.\n",
      "  warnings.warn(\"torch.nn.parallel.DistributedDataParallelCPU is deprecated, \"\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "world_size = 3\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallelCPU as DDP\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = '10.0.1.121'\n",
    "    os.environ['MASTER_PORT'] = '8890'\n",
    "    os.environ['GLOO_SOCKET_IFNAME'] = 'ens3'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(backend='gloo', \n",
    "                            init_method='env://', rank=rank, world_size=world_size)\n",
    "\n",
    "    # Explicitly setting seed to make sure that models created in two processes\n",
    "    # start from same random weights and biases.\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "setup(rank = rank, world_size = world_size)\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "hid1 = 120\n",
    "hid2 = 84\n",
    "out_size = 10\n",
    "\n",
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 1, out_channels = 6,\n",
    "            kernel_size=5, stride = 1\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = 6, out_channels = 16,\n",
    "            kernel_size=5, stride = 1\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(\n",
    "            kernel_size = 2, stride = 2\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features = 256,\n",
    "            out_features = 120\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features = 120,\n",
    "            out_features = 84\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features = 84,\n",
    "            out_features = 10\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = torch.tanh(self.conv1(img))\n",
    "        out = self.pool(out)\n",
    "        \n",
    "        out = torch.tanh(self.conv2(out))\n",
    "        out = self.pool(out)\n",
    "        \n",
    "        out = self.flat(out)\n",
    "        \n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.flat(out)\n",
    "        \n",
    "        out = torch.tanh(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='../data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas = world_size,\n",
    "        rank = rank\n",
    "    )\n",
    "\n",
    "# test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "#         test_dataset,\n",
    "#         num_replicas = world_size,\n",
    "#         rank = rank\n",
    "#     )\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler = train_sampler)\n",
    "#                                            shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "#                                           sampler = test_sampler)\n",
    "                                          shuffle=False)\n",
    "\n",
    "model = Cnn()\n",
    "\n",
    "model = DDP(model)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def train():\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            labels = labels\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "def test():\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            labels = labels\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/200], Loss: 1.0251\n",
      "Epoch [1/10], Step [200/200], Loss: 0.5322\n",
      "Epoch [2/10], Step [100/200], Loss: 0.4133\n",
      "Epoch [2/10], Step [200/200], Loss: 0.3862\n",
      "Epoch [3/10], Step [100/200], Loss: 0.2798\n",
      "Epoch [3/10], Step [200/200], Loss: 0.2977\n",
      "Epoch [4/10], Step [100/200], Loss: 0.2041\n",
      "Epoch [4/10], Step [200/200], Loss: 0.2294\n",
      "Epoch [5/10], Step [100/200], Loss: 0.1615\n",
      "Epoch [5/10], Step [200/200], Loss: 0.1794\n",
      "Epoch [6/10], Step [100/200], Loss: 0.1317\n",
      "Epoch [6/10], Step [200/200], Loss: 0.1514\n",
      "Epoch [7/10], Step [100/200], Loss: 0.1107\n",
      "Epoch [7/10], Step [200/200], Loss: 0.1367\n",
      "Epoch [8/10], Step [100/200], Loss: 0.0957\n",
      "Epoch [8/10], Step [200/200], Loss: 0.1277\n",
      "Epoch [9/10], Step [100/200], Loss: 0.0845\n",
      "Epoch [9/10], Step [200/200], Loss: 0.1211\n",
      "Epoch [10/10], Step [100/200], Loss: 0.0758\n",
      "Epoch [10/10], Step [200/200], Loss: 0.1158\n",
      "-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Name                                 Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  \n",
      "-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "mkldnn_convolution_backward          47.03%           37.071s          47.03%           37.071s          9.268ms          4000             \n",
      "mkldnn_convolution                   8.61%            6.788s           8.61%            6.788s           1.697ms          4000             \n",
      "div                                  5.28%            4.160s           5.28%            4.160s           20.801us         200000           \n",
      "avg_pool2d_backward                  4.16%            3.277s           4.16%            3.277s           819.210us        4000             \n",
      "tanh                                 3.69%            2.906s           3.69%            2.906s           363.209us        8000             \n",
      "to                                   3.50%            2.756s           4.57%            3.605s           17.848us         202000           \n",
      "view                                 3.23%            2.542s           3.23%            2.542s           10.169us         250000           \n",
      "select                               2.99%            2.357s           2.99%            2.357s           5.892us          400000           \n",
      "transpose                            2.93%            2.308s           2.93%            2.308s           5.769us          400000           \n",
      "avg_pool2d                           2.87%            2.262s           2.87%            2.262s           565.529us        4000             \n",
      "tanh_backward                        2.49%            1.964s           2.49%            1.964s           245.451us        8000             \n",
      "empty                                2.46%            1.936s           2.46%            1.936s           4.840us          400000           \n",
      "mm                                   2.38%            1.873s           2.38%            1.873s           156.052us        12000            \n",
      "set_                                 1.43%            1.125s           1.43%            1.125s           5.623us          200000           \n",
      "addmm                                1.13%            887.256ms        1.13%            887.256ms        147.876us        6000             \n",
      "stack                                0.96%            756.656ms        0.96%            756.656ms        378.328us        2000             \n",
      "add_                                 0.58%            453.512ms        0.58%            453.512ms        11.341us         39990            \n",
      "item                                 0.55%            436.913ms        1.10%            865.989ms        4.329us          200030           \n",
      "_local_scalar_dense                  0.54%            429.075ms        0.54%            429.075ms        2.145us          200030           \n",
      "slice                                0.42%            330.503ms        0.42%            330.503ms        8.263us          40000            \n",
      "unsigned short                       0.40%            314.752ms        0.40%            314.752ms        10.492us         30000            \n",
      "div_                                 0.26%            208.550ms        0.26%            208.550ms        104.275us        2000             \n",
      "sum                                  0.22%            176.079ms        0.22%            176.079ms        29.346us         6000             \n",
      "narrow                               0.20%            160.204ms        0.62%            490.707ms        12.268us         40000            \n",
      "zero_                                0.19%            150.761ms        0.19%            150.761ms        7.542us          19990            \n",
      "AddmmBackward                        0.18%            143.534ms        2.79%            2.201s           366.810us        6000             \n",
      "_log_softmax                         0.18%            143.103ms        0.18%            143.103ms        71.552us         2000             \n",
      "_log_softmax_backward_data           0.14%            106.638ms        0.14%            106.638ms        53.319us         2000             \n",
      "nll_loss_backward                    0.13%            105.353ms        0.13%            105.353ms        52.677us         2000             \n",
      "torch::autograd::AccumulateGrad      0.12%            92.376ms         0.44%            349.793ms        17.490us         20000            \n",
      "_convolution                         0.11%            89.279ms         8.74%            6.890s           1.722ms          4000             \n",
      "TanhBackward                         0.10%            78.721ms         2.59%            2.042s           255.291us        8000             \n",
      "MkldnnConvolutionBackward            0.09%            70.808ms         47.12%           37.142s          9.285ms          4000             \n",
      "nll_loss_forward                     0.08%            60.472ms         0.08%            60.472ms         30.236us         2000             \n",
      "NllLossBackward                      0.06%            50.495ms         0.20%            155.849ms        77.924us         2000             \n",
      "AvgPool2DBackward                    0.05%            40.559ms         4.21%            3.317s           829.350us        4000             \n",
      "detach_                              0.04%            30.117ms         0.04%            30.117ms         1.370us          21990            \n",
      "LogSoftmaxBackward                   0.03%            22.927ms         0.16%            129.565ms        64.783us         2000             \n",
      "reshape                              0.03%            22.178ms         0.11%            86.576ms         21.644us         4000             \n",
      "TBackward                            0.03%            20.916ms         0.08%            61.509ms         10.251us         6000             \n",
      "conv2d                               0.03%            20.450ms         8.79%            6.930s           1.732ms          4000             \n",
      "flatten                              0.02%            19.695ms         0.10%            74.889ms         18.722us         4000             \n",
      "convolution                          0.02%            19.597ms         8.77%            6.909s           1.727ms          4000             \n",
      "log_softmax                          0.02%            13.121ms         0.20%            156.224ms        78.112us         2000             \n",
      "contiguous                           0.02%            12.162ms         0.02%            12.162ms         1.014us          12000            \n",
      "nll_loss                             0.02%            12.050ms         0.09%            72.522ms         36.261us         2000             \n",
      "ViewBackward                         0.01%            10.822ms         0.05%            42.205ms         21.102us         2000             \n",
      "torch::autograd::GraphRoot           0.01%            4.930ms          0.01%            4.930ms          2.465us          2000             \n",
      "random_                              0.00%            236.365us        0.00%            236.365us        23.636us         10               \n",
      "is_floating_point                    0.00%            69.789us         0.00%            69.789us         2.326us          30               \n",
      "detach                               0.00%            26.224us         0.00%            26.224us         2.622us          10               \n",
      "is_complex                           0.00%            9.245us          0.00%            9.245us          0.924us          10               \n",
      "-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Self CPU time total: 78.819s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 97.99 %\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with torch.autograd.profiler.profile(use_cuda=False) as prof:\n",
    "        train()\n",
    "    tbl = prof.key_averages().table(sort_by=\"self_cpu_time_total\")\n",
    "    print(tbl)\n",
    "    \n",
    "    test()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
