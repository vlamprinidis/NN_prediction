{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.7/site-packages/torch/nn/parallel/__init__.py:12: UserWarning: torch.nn.parallel.DistributedDataParallelCPU is deprecated, please use torch.nn.parallel.DistributedDataParallel instead.\n",
      "  warnings.warn(\"torch.nn.parallel.DistributedDataParallelCPU is deprecated, \"\n"
     ]
    }
   ],
   "source": [
    "rank = 0\n",
    "world_size = 3\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallelCPU as DDP\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = '10.0.1.121'\n",
    "    os.environ['MASTER_PORT'] = '8890'\n",
    "    os.environ['GLOO_SOCKET_IFNAME'] = 'ens3'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(backend='gloo', \n",
    "                            init_method='env://', rank=rank, world_size=world_size)\n",
    "\n",
    "    # Explicitly setting seed to make sure that models created in two processes\n",
    "    # start from same random weights and biases.\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "setup(rank = rank, world_size = world_size)\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "hid1 = 120\n",
    "hid2 = 84\n",
    "out_size = 10\n",
    "\n",
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 1, out_channels = 6,\n",
    "            kernel_size=5, stride = 1\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = 6, out_channels = 16,\n",
    "            kernel_size=5, stride = 1\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(\n",
    "            kernel_size = 2, stride = 2\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features = 256,\n",
    "            out_features = 120\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features = 120,\n",
    "            out_features = 84\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features = 84,\n",
    "            out_features = 10\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = torch.tanh(self.conv1(img))\n",
    "        out = self.pool(out)\n",
    "        \n",
    "        out = torch.tanh(self.conv2(out))\n",
    "        out = self.pool(out)\n",
    "        \n",
    "        out = self.flat(out)\n",
    "        \n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.flat(out)\n",
    "        \n",
    "        out = torch.tanh(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='../data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas = world_size,\n",
    "        rank = rank\n",
    "    )\n",
    "\n",
    "# test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "#         test_dataset,\n",
    "#         num_replicas = world_size,\n",
    "#         rank = rank\n",
    "#     )\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler = train_sampler)\n",
    "#                                            shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "#                                           sampler = test_sampler)\n",
    "                                          shuffle=False)\n",
    "\n",
    "model = Cnn()\n",
    "\n",
    "model = DDP(model)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def train():\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            labels = labels\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "def test():\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            labels = labels\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Name                                 Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  \n",
      "-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "mkldnn_convolution_backward          40.99%           831.094ms        40.99%           831.094ms        415.547ms        2                \n",
      "mkldnn_convolution                   23.44%           475.346ms        23.44%           475.346ms        237.673ms        2                \n",
      "avg_pool2d_backward                  10.46%           212.096ms        10.46%           212.096ms        106.048ms        2                \n",
      "avg_pool2d                           8.05%            163.123ms        8.05%            163.123ms        81.561ms         2                \n",
      "tanh                                 7.47%            151.411ms        7.47%            151.411ms        37.853ms         4                \n",
      "tanh_backward                        6.75%            136.796ms        6.75%            136.796ms        34.199ms         4                \n",
      "mm                                   1.87%            37.843ms         1.87%            37.843ms         6.307ms          6                \n",
      "addmm                                0.52%            10.461ms         0.52%            10.461ms         3.487ms          3                \n",
      "sum                                  0.22%            4.471ms          0.22%            4.471ms          1.490ms          3                \n",
      "_log_softmax                         0.06%            1.282ms          0.06%            1.282ms          1.282ms          1                \n",
      "_log_softmax_backward_data           0.05%            1.060ms          0.05%            1.060ms          1.060ms          1                \n",
      "nll_loss_backward                    0.04%            727.734us        0.04%            727.734us        727.734us        1                \n",
      "div_                                 0.01%            252.977us        0.01%            252.977us        252.977us        1                \n",
      "view                                 0.01%            223.239us        0.01%            223.239us        8.930us          25               \n",
      "unsigned short                       0.01%            164.580us        0.01%            164.580us        10.972us         15               \n",
      "nll_loss_forward                     0.01%            156.851us        0.01%            156.851us        156.851us        1                \n",
      "slice                                0.01%            152.417us        0.01%            152.417us        7.621us          20               \n",
      "AddmmBackward                        0.00%            92.579us         1.88%            38.039ms         12.680ms         3                \n",
      "TanhBackward                         0.00%            85.890us         6.75%            136.882ms        34.220ms         4                \n",
      "MkldnnConvolutionBackward            0.00%            77.794us         40.99%           831.172ms        415.586ms        2                \n",
      "conv2d                               0.00%            72.080us         23.45%           475.499ms        237.749ms        2                \n",
      "torch::autograd::AccumulateGrad      0.00%            71.744us         0.01%            105.955us        10.596us         10               \n",
      "add_                                 0.00%            71.413us         0.00%            71.413us         7.141us          10               \n",
      "_convolution                         0.00%            60.895us         23.45%           475.410ms        237.705ms        2                \n",
      "AvgPool2DBackward                    0.00%            51.754us         10.46%           212.148ms        106.074ms        2                \n",
      "LogSoftmaxBackward                   0.00%            46.315us         0.05%            1.106ms          1.106ms          1                \n",
      "NllLossBackward                      0.00%            37.160us         0.04%            764.894us        764.894us        1                \n",
      "narrow                               0.00%            35.883us         0.01%            188.300us        9.415us          20               \n",
      "detach                               0.00%            34.211us         0.00%            34.211us         3.421us          10               \n",
      "nll_loss                             0.00%            17.555us         0.01%            174.406us        174.406us        1                \n",
      "log_softmax                          0.00%            16.898us         0.06%            1.299ms          1.299ms          1                \n",
      "flatten                              0.00%            16.725us         0.00%            63.622us         31.811us         2                \n",
      "convolution                          0.00%            15.986us         23.45%           475.426ms        237.713ms        2                \n",
      "reshape                              0.00%            15.306us         0.00%            54.775us         27.388us         2                \n",
      "TBackward                            0.00%            13.292us         0.00%            27.651us         9.217us          3                \n",
      "contiguous                           0.00%            4.099us          0.00%            4.099us          0.683us          6                \n",
      "ViewBackward                         0.00%            3.092us          0.00%            10.970us         10.970us         1                \n",
      "torch::autograd::GraphRoot           0.00%            3.012us          0.00%            3.012us          3.012us          1                \n",
      "-----------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Self CPU time total: 2.028s\n",
      "\n",
      "Test Accuracy of the model on the 10000 test images: 9.79 %\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with torch.autograd.profiler.profile(use_cuda=False) as prof:\n",
    "        train()\n",
    "    tbl = prof.key_averages().table(sort_by=\"self_cpu_time_total\")\n",
    "    print(tbl)\n",
    "    \n",
    "    test()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
